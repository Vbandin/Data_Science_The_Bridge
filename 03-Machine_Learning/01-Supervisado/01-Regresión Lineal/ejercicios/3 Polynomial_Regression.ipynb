{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lObjyER4X6p"
   },
   "source": [
    "## Polynomial Regression on Boston Housing Dataset\n",
    "\n",
    "**In this notebook we do a comparative study of Linear Regression and Polynomial Regression accuracy on the Boston Housing Dataset**\n",
    "\n",
    "This data was originally a part of UCI Machine Learning Repository and has been removed now. This data also ships with the scikit-learn library. \n",
    "There are 506 samples and 13 feature variables in this data-set. The objective is to predict the value of prices of the house using the given features.\n",
    "\n",
    "The description of all the features is given below:\n",
    "\n",
    "  **CRIM**: Per capita crime rate by town\n",
    "\n",
    "  **ZN**: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "\n",
    "  **INDUS**: Proportion of non-retail business acres per town\n",
    "\n",
    "  **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "  **NOX**: Nitric oxide concentration (parts per 10 million)\n",
    "\n",
    "  **RM**: Average number of rooms per dwelling\n",
    "\n",
    "  **AGE**: Proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "  **DIS**: Weighted distances to five Boston employment centers\n",
    "\n",
    "  **RAD**: Index of accessibility to radial highways\n",
    "\n",
    "  **TAX**: Full-value property tax rate per $10,000\n",
    "\n",
    "  **B**: 1000(Bk - 0.63)Â², where Bk is the proportion of [people of African American descent] by town\n",
    "\n",
    "  **LSTAT**: Percentage of lower status of the population\n",
    "\n",
    "  **MEDV**: Median value of owner-occupied homes in $1000s\n",
    "  \n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gorjhNWk1jYI"
   },
   "source": [
    "I**mport the required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICB6ibhd1oo6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZluhUmFzgwN"
   },
   "source": [
    "**Load the Boston Housing DataSet from scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GgjfA1CJ19_K",
    "outputId": "e2caf803-5941-4983-a1b5-dbb3861b75f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boston_dataset is a dictionary. let's check what it contains**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'featured_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12056\\1150012429.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mboston_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'featured_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'featured_names'"
     ]
    }
   ],
   "source": [
    "boston_dataset['features_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-egcQr3zrr0"
   },
   "source": [
    "**Load the data into pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ve1ycomY2QDg",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2a724ab8-35a8-42fb-b76c-1cf4b0208626"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12056\\1781716891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboston_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(boston_dataset['data'], columns=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVlhiwrEz0CQ"
   },
   "source": [
    "**The target values is missing from the data. Create a new column of target values and add it to dataframe in a column called MEDV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95OyiHWb3iXR"
   },
   "outputs": [],
   "source": [
    "df['MEDV'] = boston_dataset['target']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G01Hoq3g0BDp"
   },
   "source": [
    "**Data preprocessing**\n",
    "\n",
    "Check for missing values in all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "IbPhXLY54FA_",
    "outputId": "bb502fb0-0ac4-4449-8f43-aaca3d339ce4"
   },
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inz3dJr00K6y"
   },
   "source": [
    "**Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "colab_type": "code",
    "id": "pQ95WeqQ4rOa",
    "outputId": "4877a114-3267-4641-afec-8e161ec097a5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IBNTU5N0RQ5"
   },
   "source": [
    "**Correlation matrix**\n",
    "\n",
    "Analyze the correlation matrix. Plot a heatmap\n",
    "\n",
    "\n",
    "*   From coorelation plot: which are the columns that are more highli correlated with **MEDV**\n",
    "\n",
    "* There are two features highly correlated. Identify them and drop one of them in order to avoid multi-colinearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aOQvsTM46Bi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13,10))\n",
    "sns.heatmap(df.corr(),\n",
    "           annot=True,\n",
    "           linewidths=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.abs(df.corr()['MEDV']).sort_values(ascending=False)\n",
    "# Ordenamos las variables por su correlacion con el target para elegir las mas importantes\n",
    "# Elimino RAD porque esta muy correlacionada con TAX y tax tiene una mayor correlacion con el target (MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos variables con alta correlacion para evitar la multcolinearidad\n",
    "df.drop(columns='RAD', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw 2 scatter plots to see the relationship between **MEDV** and **LSTAT** and **RM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Vbf0Z3u-vgb"
   },
   "source": [
    "**Prepare the data for training**\n",
    "Create a dataframe X including **LSTAT** and **RM** columns.\n",
    "Y should be a pandas series including target values **'MEDV'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-xFbFH1Apu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qloWQhqb0fud"
   },
   "source": [
    "**Split the data into training and testing sets**\n",
    "\n",
    "Splits the training and test data set in 80% : 20%. Assign random_state to any value. This ensures consistency. Print the sahes of the resulting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JSBuka3Eecm"
   },
   "source": [
    "# **Linear Regression**\n",
    "\n",
    "Build a linear regression model with sklearn LinearRegression.\n",
    "We'll use Mean Squared error and R2 score to evaluate our model, so be sure to make the needed imports.\n",
    "\n",
    "Import the necessary functions and train a LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model performance in the training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets see the model performance visually. Let's plot y_test vs y_pred**\n",
    "\n",
    "Plotting the y_test vs y_pred. Ideally should have been a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "GFZQxWLtV2WS",
    "outputId": "b1945395-a7c9-4b71-c134-ff7774df740c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJuZfJHwfhfa"
   },
   "source": [
    "# **Polynomial Regression**\n",
    "\n",
    "We can see that **LSTAT** doesn't vary exactly in a linear way. Let's apply the Polynomial Regression with **degree 2** and test. \n",
    "\n",
    "To generate the higher order degrees, we use PolyniomialFeatures class from sklearn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilTGxJJpDyDd"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "poly_reg,fit(X_train)\n",
    "\n",
    "X_poly = poly_reg.transform(X_train)\n",
    "\n",
    "pd.DataFrame(X_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5wzgDBShTUh"
   },
   "source": [
    "**Did the model improve using the plolynomila model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Polynomial Regression on Boston Housing Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
